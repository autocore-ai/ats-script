# -*- coding:utf8 -*-
"""
Perception:
    处理现场录制的rosbag, 获取感知模块topic，并输出障碍物的基准信息

处理步骤：
    1. 启动环境，本地 Autoware4 环境，Xavier(192.168.10.54)提供perception环境
    2. 开启记录topic脚本： /perception/object_recognition/objects
    3. 开始播放现场rosbag
    4. 等待播放完成
    5. 给出topic记录结果

Topics 记录存储形式：
    1. 记录为bag -- 有点
    2. 记录为CSV
    3. 记录为TXT


Topic 记录处理结果：
    1. 障碍物UUID数量uuid_count，检出率: uuid_count/t，给出每秒检出UUID的数量，并画出折线图
    2. 障碍物正确的semantic，出现的semantic类型和分别对应的数量，正确语义所占的百分比，语义饼状图，语义每秒的折线图，不同的语义不同的折线图
    3. 障碍物的position，取x,y的值，按照时间顺序组成二维list，并画出折线图
    4. 障碍物的orientation，计算偏航角，按照时间顺序组成list，并画出折线图
    5. 障碍物的线速度line，只取x和y的值，X轴数据按照时间顺序组成list，并画出折线图, Y轴数据按照时间顺序组成list，并画出折线图，并给出X和Y的平均速度
    6. 障碍物的预测数据，取出每个点预测信息的第二个值，第二个值预测的是当前障碍物在0.5s后，所在的位置和方向。像第2和3一样获取list，然后画出和3,4相比较的折线图，预测数据的折线图，X轴的起点较3和4的要晚0.5s。
        后期可将预测的数据和3和4的数据分别做欧氏距离和余弦相似性处理，并计算标准方差，以做数据参考
    7. 障碍物的shape, 出现的shape类型和对应的数量，正确类型所占的百分比，shape饼状图。按照时间顺序分别组成X和Y的list，并画出折线图。分别计算X和Y的标准方差

脚本适用障碍物类型范围：
    bag中只有一个障碍物所有类型

"""

